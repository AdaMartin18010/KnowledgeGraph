#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±é¡¹ç›®ç®¡ç†å·¥å…· / Knowledge Graph Project Management Tool
ç”¨äºè‡ªåŠ¨åŒ–æ£€æŸ¥æ–‡æ¡£è´¨é‡ã€ç”Ÿæˆè¿›åº¦æŠ¥å‘Šå’Œç®¡ç†äº¤å‰å¼•ç”¨
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class DocumentMetrics:
    """æ–‡æ¡£è´¨é‡æŒ‡æ ‡"""
    file_path: str
    word_count: int
    bilingual_ratio: float
    has_formal_proofs: bool
    has_code_examples: bool
    has_critical_analysis: bool
    has_references: bool
    internal_links: List[str]
    external_links: List[str]

class KnowledgeGraphProjectManager:
    """çŸ¥è¯†å›¾è°±é¡¹ç›®ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.docs_dir = self.project_root / "docs"
        self.tools_dir = self.project_root / "tools"
        self.reports_dir = self.project_root / "reports"
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self.reports_dir.mkdir(exist_ok=True)
        
    def scan_documents(self) -> List[DocumentMetrics]:
        """æ‰«ææ‰€æœ‰æ–‡æ¡£å¹¶æ”¶é›†æŒ‡æ ‡"""
        metrics = []
        
        for doc_file in self.docs_dir.rglob("*.md"):
            if doc_file.name == "template.md":
                continue
                
            metrics.append(self._analyze_document(doc_file))
            
        return metrics
    
    def _analyze_document(self, file_path: Path) -> DocumentMetrics:
        """åˆ†æå•ä¸ªæ–‡æ¡£"""
        content = file_path.read_text(encoding='utf-8')
        
        # å­—æ•°ç»Ÿè®¡
        word_count = len(content.split())
        
        # åŒè¯­æ¯”ä¾‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))
        bilingual_ratio = min(chinese_chars, english_chars) / max(chinese_chars, english_chars) if max(chinese_chars, english_chars) > 0 else 0
        
        # æ£€æŸ¥å„ç§è¦ç´ 
        has_formal_proofs = bool(re.search(r'å®šç†|Theorem|è¯æ˜|Proof', content))
        has_code_examples = bool(re.search(r'```(rust|haskell|lean)', content))
        has_critical_analysis = bool(re.search(r'æ‰¹åˆ¤æ€§åˆ†æ|Critical Analysis', content))
        has_references = bool(re.search(r'å‚è€ƒæ–‡çŒ®|References', content))
        
        # é“¾æ¥æå–
        internal_links = re.findall(r'\[([^\]]+)\]\(\.\./[^)]+\)', content)
        external_links = re.findall(r'\[([^\]]+)\]\(https?://[^)]+\)', content)
        
        return DocumentMetrics(
            file_path=str(file_path.relative_to(self.project_root)),
            word_count=word_count,
            bilingual_ratio=bilingual_ratio,
            has_formal_proofs=has_formal_proofs,
            has_code_examples=has_code_examples,
            has_critical_analysis=has_critical_analysis,
            has_references=has_references,
            internal_links=internal_links,
            external_links=external_links
        )
    
    def generate_progress_report(self) -> Dict:
        """ç”Ÿæˆé¡¹ç›®è¿›åº¦æŠ¥å‘Š"""
        metrics = self.scan_documents()
        
        total_docs = len(metrics)
        completed_docs = sum(1 for m in metrics if m.word_count > 1000)
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        avg_bilingual_ratio = sum(m.bilingual_ratio for m in metrics) / len(metrics) if metrics else 0
        docs_with_proofs = sum(1 for m in metrics if m.has_formal_proofs)
        docs_with_code = sum(1 for m in metrics if m.has_code_examples)
        docs_with_analysis = sum(1 for m in metrics if m.has_critical_analysis)
        docs_with_refs = sum(1 for m in metrics if m.has_references)
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "project_status": {
                "total_documents": total_docs,
                "completed_documents": completed_docs,
                "completion_rate": completed_docs / total_docs if total_docs > 0 else 0
            },
            "quality_metrics": {
                "average_bilingual_ratio": avg_bilingual_ratio,
                "documents_with_formal_proofs": docs_with_proofs,
                "documents_with_code_examples": docs_with_code,
                "documents_with_critical_analysis": docs_with_analysis,
                "documents_with_references": docs_with_refs
            },
            "document_details": [
                {
                    "file": m.file_path,
                    "word_count": m.word_count,
                    "bilingual_ratio": m.bilingual_ratio,
                    "has_formal_proofs": m.has_formal_proofs,
                    "has_code_examples": m.has_code_examples,
                    "has_critical_analysis": m.has_critical_analysis,
                    "has_references": m.has_references,
                    "internal_links": m.internal_links,
                    "external_links": m.external_links
                }
                for m in metrics
            ]
        }
        
        return report
    
    def save_report(self, report: Dict, filename: str = None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            filename = f"progress_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report_path = self.reports_dir / filename
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    def generate_markdown_report(self, report: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        md_content = f"""# çŸ¥è¯†å›¾è°±é¡¹ç›®è¿›åº¦æŠ¥å‘Š / Knowledge Graph Project Progress Report

## ç”Ÿæˆæ—¶é—´ / Generated Time
{report['timestamp']}

## é¡¹ç›®çŠ¶æ€ / Project Status

| æŒ‡æ ‡ / Metric | æ•°å€¼ / Value |
|--------------|-------------|
| æ€»æ–‡æ¡£æ•° / Total Documents | {report['project_status']['total_documents']} |
| å·²å®Œæˆæ–‡æ¡£ / Completed Documents | {report['project_status']['completed_documents']} |
| å®Œæˆç‡ / Completion Rate | {report['project_status']['completion_rate']:.2%} |

## è´¨é‡æŒ‡æ ‡ / Quality Metrics

| æŒ‡æ ‡ / Metric | æ•°å€¼ / Value |
|--------------|-------------|
| å¹³å‡åŒè¯­æ¯”ä¾‹ / Average Bilingual Ratio | {report['quality_metrics']['average_bilingual_ratio']:.2%} |
| åŒ…å«å½¢å¼åŒ–è¯æ˜çš„æ–‡æ¡£ / Documents with Formal Proofs | {report['quality_metrics']['documents_with_formal_proofs']} |
| åŒ…å«ä»£ç ç¤ºä¾‹çš„æ–‡æ¡£ / Documents with Code Examples | {report['quality_metrics']['documents_with_code_examples']} |
| åŒ…å«æ‰¹åˆ¤æ€§åˆ†æçš„æ–‡æ¡£ / Documents with Critical Analysis | {report['quality_metrics']['documents_with_critical_analysis']} |
| åŒ…å«å‚è€ƒæ–‡çŒ®çš„æ–‡æ¡£ / Documents with References | {report['quality_metrics']['documents_with_references']} |

## æ–‡æ¡£è¯¦æƒ… / Document Details

"""
        
        for doc in report['document_details']:
            md_content += f"""### {doc['file']}

- **å­—æ•°** / Word Count: {doc['word_count']}
- **åŒè¯­æ¯”ä¾‹** / Bilingual Ratio: {doc['bilingual_ratio']:.2%}
- **å½¢å¼åŒ–è¯æ˜** / Formal Proofs: {'âœ“' if doc['has_formal_proofs'] else 'âœ—'}
- **ä»£ç ç¤ºä¾‹** / Code Examples: {'âœ“' if doc['has_code_examples'] else 'âœ—'}
- **æ‰¹åˆ¤æ€§åˆ†æ** / Critical Analysis: {'âœ“' if doc['has_critical_analysis'] else 'âœ—'}
- **å‚è€ƒæ–‡çŒ®** / References: {'âœ“' if doc['has_references'] else 'âœ—'}
- **å†…éƒ¨é“¾æ¥** / Internal Links: {len(doc['internal_links'])}
- **å¤–éƒ¨é“¾æ¥** / External Links: {len(doc['external_links'])}

"""
        
        return md_content
    
    def check_consistency(self) -> Dict:
        """æ£€æŸ¥é¡¹ç›®ä¸€è‡´æ€§"""
        issues = []
        
        # æ£€æŸ¥ç›®å½•ç»“æ„
        expected_dirs = [
            "01-knowledge-representation",
            "02-graph-theory", 
            "03-semantic-analysis",
            "04-ontology-engineering",
            "05-knowledge-extraction",
            "06-reasoning-systems",
            "07-applications",
            "08-formal-methods",
            "09-engineering-practices",
            "10-research-methodology"
        ]
        
        for dir_name in expected_dirs:
            dir_path = self.docs_dir / dir_name
            if not dir_path.exists():
                issues.append(f"ç¼ºå°‘ç›®å½•: {dir_name}")
            elif not (dir_path / "README.md").exists():
                issues.append(f"ç¼ºå°‘READMEæ–‡ä»¶: {dir_name}/README.md")
        
        # æ£€æŸ¥äº¤å‰å¼•ç”¨
        metrics = self.scan_documents()
        for metric in metrics:
            for link in metric.internal_links:
                # æ£€æŸ¥å†…éƒ¨é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
                if not self._check_internal_link(link):
                    issues.append(f"æ— æ•ˆçš„å†…éƒ¨é“¾æ¥: {metric.file_path} -> {link}")
        
        return {
            "issues": issues,
            "issue_count": len(issues)
        }
    
    def _check_internal_link(self, link_text: str) -> bool:
        """æ£€æŸ¥å†…éƒ¨é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"""
        # ç®€åŒ–çš„é“¾æ¥æ£€æŸ¥é€»è¾‘
        return any(link_text.lower() in dir_name.lower() 
                  for dir_name in os.listdir(self.docs_dir))
    
    def generate_next_steps(self, report: Dict) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’"""
        steps = []
        
        completion_rate = report['project_status']['completion_rate']
        if completion_rate < 0.5:
            steps.append("ä¼˜å…ˆå®Œæˆæ ¸å¿ƒæ¨¡å—çš„å†…å®¹å¼€å‘")
        
        avg_bilingual = report['quality_metrics']['average_bilingual_ratio']
        if avg_bilingual < 0.8:
            steps.append("åŠ å¼ºåŒè¯­å¯¹ç…§çš„å®Œå–„")
        
        docs_with_proofs = report['quality_metrics']['documents_with_formal_proofs']
        total_docs = report['project_status']['total_documents']
        if docs_with_proofs < total_docs * 0.8:
            steps.append("å¢åŠ å½¢å¼åŒ–è¯æ˜çš„å†…å®¹")
        
        consistency_check = self.check_consistency()
        if consistency_check['issue_count'] > 0:
            steps.append("ä¿®å¤é¡¹ç›®ä¸€è‡´æ€§é—®é¢˜")
        
        return steps

def main():
    """ä¸»å‡½æ•°"""
    manager = KnowledgeGraphProjectManager()
    
    print("ğŸ” æ‰«æé¡¹ç›®æ–‡æ¡£...")
    report = manager.generate_progress_report()
    
    print("ğŸ“Š ç”Ÿæˆè¿›åº¦æŠ¥å‘Š...")
    manager.save_report(report)
    
    print("ğŸ“ ç”ŸæˆMarkdownæŠ¥å‘Š...")
    md_report = manager.generate_markdown_report(report)
    report_path = manager.reports_dir / f"progress_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(md_report)
    
    print("ğŸ” æ£€æŸ¥é¡¹ç›®ä¸€è‡´æ€§...")
    consistency = manager.check_consistency()
    
    print("ğŸ“‹ ç”Ÿæˆä¸‹ä¸€æ­¥è®¡åˆ’...")
    next_steps = manager.generate_next_steps(report)
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "="*50)
    print("ğŸ“ˆ é¡¹ç›®è¿›åº¦æ‘˜è¦ / Project Progress Summary")
    print("="*50)
    print(f"æ€»æ–‡æ¡£æ•°: {report['project_status']['total_documents']}")
    print(f"å®Œæˆç‡: {report['project_status']['completion_rate']:.2%}")
    print(f"å¹³å‡åŒè¯­æ¯”ä¾‹: {report['quality_metrics']['average_bilingual_ratio']:.2%}")
    print(f"ä¸€è‡´æ€§é—®é¢˜: {consistency['issue_count']} ä¸ª")
    
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’ / Next Action Plan:")
    for i, step in enumerate(next_steps, 1):
        print(f"{i}. {step}")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {manager.reports_dir}")

if __name__ == "__main__":
    main() 