#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒè¯­ä¼˜åŒ–å·¥å…· / Bilingual Optimization Tool
ç”¨äºæå‡æ–‡æ¡£çš„åŒè¯­æ¯”ä¾‹ï¼Œç¡®ä¿ä¸­è‹±å¯¹ç…§çš„å®Œæ•´æ€§
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class BilingualSection:
    """åŒè¯­æ®µè½ç»“æ„"""
    chinese_text: str
    english_text: str
    section_type: str
    line_number: int

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    file_path: str
    original_ratio: float
    optimized_ratio: float
    improvements: List[str]
    suggestions: List[str]

class BilingualOptimizer:
    """åŒè¯­ä¼˜åŒ–å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.docs_dir = project_root / "docs"
        
    def analyze_document(self, file_path: Path) -> Dict:
        """åˆ†ææ–‡æ¡£çš„åŒè¯­æƒ…å†µ"""
        content = file_path.read_text(encoding='utf-8')
        lines = content.split('\n')
        
        # ç»Ÿè®¡ä¸­è‹±æ–‡å­—ç¬¦
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))
        
        # è®¡ç®—åŒè¯­æ¯”ä¾‹
        total_chars = chinese_chars + english_chars
        bilingual_ratio = min(chinese_chars, english_chars) / max(chinese_chars, english_chars) if max(chinese_chars, english_chars) > 0 else 0
        
        # åˆ†ææ®µè½ç»“æ„
        sections = self._extract_sections(lines)
        
        return {
            'file_path': str(file_path.relative_to(self.project_root)),
            'chinese_chars': chinese_chars,
            'english_chars': english_chars,
            'total_chars': total_chars,
            'bilingual_ratio': bilingual_ratio,
            'sections': sections
        }
    
    def _extract_sections(self, lines: List[str]) -> List[BilingualSection]:
        """æå–åŒè¯­æ®µè½"""
        sections = []
        current_chinese = []
        current_english = []
        current_type = ""
        line_num = 0
        
        for line in lines:
            line_num += 1
            
            # æ£€æµ‹æ®µè½ç±»å‹
            if line.startswith('##'):
                current_type = "section"
            elif line.startswith('###'):
                current_type = "subsection"
            elif line.startswith('|'):
                current_type = "table"
            elif line.startswith('```'):
                current_type = "code"
            else:
                current_type = "text"
            
            # åˆ†ç¦»ä¸­è‹±æ–‡å†…å®¹
            chinese_part = re.sub(r'[a-zA-Z\s]*', '', line)
            english_part = re.sub(r'[\u4e00-\u9fff\s]*', '', line)
            
            if chinese_part.strip() and english_part.strip():
                # åŒè¯­è¡Œ
                sections.append(BilingualSection(
                    chinese_text=chinese_part.strip(),
                    english_text=english_part.strip(),
                    section_type=current_type,
                    line_number=line_num
                ))
            elif chinese_part.strip():
                # çº¯ä¸­æ–‡è¡Œ
                current_chinese.append(line)
            elif english_part.strip():
                # çº¯è‹±æ–‡è¡Œ
                current_english.append(line)
        
        return sections
    
    def optimize_document(self, file_path: Path) -> OptimizationResult:
        """ä¼˜åŒ–æ–‡æ¡£çš„åŒè¯­æ¯”ä¾‹"""
        analysis = self.analyze_document(file_path)
        original_ratio = analysis['bilingual_ratio']
        
        content = file_path.read_text(encoding='utf-8')
        optimized_content = self._optimize_content(content)
        
        # è®¡ç®—ä¼˜åŒ–åçš„æ¯”ä¾‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', optimized_content))
        english_chars = len(re.findall(r'[a-zA-Z]', optimized_content))
        optimized_ratio = min(chinese_chars, english_chars) / max(chinese_chars, english_chars) if max(chinese_chars, english_chars) > 0 else 0
        
        improvements = self._generate_improvements(analysis)
        suggestions = self._generate_suggestions(analysis)
        
        return OptimizationResult(
            file_path=str(file_path.relative_to(self.project_root)),
            original_ratio=original_ratio,
            optimized_ratio=optimized_ratio,
            improvements=improvements,
            suggestions=suggestions
        )
    
    def _optimize_content(self, content: str) -> str:
        """ä¼˜åŒ–å†…å®¹ï¼Œå¢åŠ è‹±æ–‡ç¿»è¯‘"""
        lines = content.split('\n')
        optimized_lines = []
        
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è‹±æ–‡ç¿»è¯‘
            if self._has_english_translation(line):
                optimized_lines.append(line)
            else:
                # å°è¯•æ·»åŠ è‹±æ–‡ç¿»è¯‘
                translated_line = self._add_english_translation(line)
                optimized_lines.append(translated_line)
        
        return '\n'.join(optimized_lines)
    
    def _has_english_translation(self, line: str) -> bool:
        """æ£€æŸ¥è¡Œæ˜¯å¦å·²æœ‰è‹±æ–‡ç¿»è¯‘"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡
        english_chars = len(re.findall(r'[a-zA-Z]', line))
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', line))
        
        return english_chars > 0 and chinese_chars > 0
    
    def _add_english_translation(self, line: str) -> str:
        """ä¸ºä¸­æ–‡è¡Œæ·»åŠ è‹±æ–‡ç¿»è¯‘"""
        if not re.search(r'[\u4e00-\u9fff]', line):
            return line
        
        # ç®€å•çš„ç¿»è¯‘æ˜ å°„
        translations = {
            'æ¦‚è¿°': 'Overview',
            'å®šä¹‰': 'Definition',
            'æ¦‚å¿µ': 'Concepts',
            'å†å²å‘å±•': 'Historical Development',
            'å‘å±•å†ç¨‹': 'Development Timeline',
            'æ ¸å¿ƒç‰¹å¾': 'Core Characteristics',
            'ç‰¹å¾': 'Features',
            'ä¸­æ–‡æè¿°': 'Chinese Description',
            'ç†è®ºåŸºç¡€': 'Theoretical Foundation',
            'æ•°å­¦åŸºç¡€': 'Mathematical Foundation',
            'å½¢å¼åŒ–å®šä¹‰': 'Formal Definition',
            'æ•°å­¦ç¬¦å·': 'Mathematical Notation',
            'å®šç†': 'Theorem',
            'è¯æ˜': 'Proof',
            'é€»è¾‘æ¡†æ¶': 'Logical Framework',
            'é€»è¾‘ç»“æ„': 'Logical Structure',
            'æ‰¹åˆ¤æ€§åˆ†æ': 'Critical Analysis',
            'ä¼˜åŠ¿åˆ†æ': 'Strengths Analysis',
            'ä¼˜åŠ¿': 'Strengths',
            'å±€é™æ€§åˆ†æ': 'Limitations Analysis',
            'å±€é™æ€§': 'Limitations',
            'äº‰è®®ä¸è®¨è®º': 'Controversies and Discussions',
            'äº‰è®®ç‚¹': 'Controversies',
            'æ”¯æŒè§‚ç‚¹': 'Supporting Views',
            'åå¯¹è§‚ç‚¹': 'Opposing Views',
            'ä¸­ç«‹åˆ†æ': 'Neutral Analysis',
            'å·¥ç¨‹å®è·µ': 'Engineering Practice',
            'å®ç°æ–¹æ³•': 'Implementation Methods',
            'ç®—æ³•è®¾è®¡': 'Algorithm Design',
            'æ•°æ®ç»“æ„': 'Data Structures',
            'æ€§èƒ½åˆ†æ': 'Performance Analysis',
            'å·¥ç¨‹æ¡ˆä¾‹': 'Engineering Cases',
            'åº”ç”¨é¢†åŸŸ': 'Application Domains',
            'ä¸»è¦åº”ç”¨': 'Primary Applications',
            'å®é™…æ¡ˆä¾‹': 'Real-world Cases',
            'å‰æ²¿å‘å±•': 'Frontier Development',
            'æœ€æ–°ç ”ç©¶': 'Latest Research',
            'å‘å±•è¶‹åŠ¿': 'Development Trends',
            'æ€»ç»“ä¸å±•æœ›': 'Summary and Prospects',
            'æ ¸å¿ƒè¦ç‚¹': 'Key Points',
            'æœªæ¥å±•æœ›': 'Future Prospects',
            'å‚è€ƒæ–‡çŒ®': 'References',
            'å­¦æœ¯æ–‡çŒ®': 'Academic Literature',
            'æŠ€æœ¯æ–‡æ¡£': 'Technical Documentation',
            'åœ¨çº¿èµ„æº': 'Online Resources',
            'ç›¸å…³é“¾æ¥': 'Related Links',
            'å†…éƒ¨é“¾æ¥': 'Internal Links',
            'å¤–éƒ¨é“¾æ¥': 'External Links',
            'æœ€åæ›´æ–°': 'Last Updated',
            'ç‰ˆæœ¬': 'Version',
            'ç»´æŠ¤è€…': 'Maintainer',
        }
        
        # å°è¯•ç¿»è¯‘
        translated_line = line
        for chinese, english in translations.items():
            if chinese in line:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è‹±æ–‡
                if not re.search(r'[a-zA-Z]', line):
                    translated_line = line.replace(chinese, f"{chinese} / {english}")
                break
        
        return translated_line
    
    def _generate_improvements(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        improvements = []
        
        if analysis['bilingual_ratio'] < 0.8:
            improvements.append("éœ€è¦å¢åŠ è‹±æ–‡ç¿»è¯‘ä»¥æé«˜åŒè¯­æ¯”ä¾‹")
        
        if analysis['chinese_chars'] > analysis['english_chars'] * 2:
            improvements.append("ä¸­æ–‡å†…å®¹è¿‡å¤šï¼Œéœ€è¦å¢åŠ è‹±æ–‡å†…å®¹")
        
        if analysis['english_chars'] > analysis['chinese_chars'] * 2:
            improvements.append("è‹±æ–‡å†…å®¹è¿‡å¤šï¼Œéœ€è¦å¢åŠ ä¸­æ–‡å†…å®¹")
        
        return improvements
    
    def _generate_suggestions(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆå…·ä½“å»ºè®®"""
        suggestions = []
        
        # åˆ†ææ®µè½ç»“æ„
        sections = analysis['sections']
        chinese_only_sections = [s for s in sections if s.chinese_text and not s.english_text]
        english_only_sections = [s for s in sections if s.english_text and not s.chinese_text]
        
        if chinese_only_sections:
            suggestions.append(f"å‘ç° {len(chinese_only_sections)} ä¸ªçº¯ä¸­æ–‡æ®µè½ï¼Œéœ€è¦æ·»åŠ è‹±æ–‡ç¿»è¯‘")
        
        if english_only_sections:
            suggestions.append(f"å‘ç° {len(english_only_sections)} ä¸ªçº¯è‹±æ–‡æ®µè½ï¼Œéœ€è¦æ·»åŠ ä¸­æ–‡ç¿»è¯‘")
        
        return suggestions
    
    def generate_report(self) -> Dict:
        """ç”ŸæˆåŒè¯­ä¼˜åŒ–æŠ¥å‘Š"""
        docs_files = list(self.docs_dir.rglob("*.md"))
        
        results = []
        total_original_ratio = 0
        total_optimized_ratio = 0
        
        for file_path in docs_files:
            if file_path.name == "template.md":
                continue
                
            result = self.optimize_document(file_path)
            results.append(result)
            total_original_ratio += result.original_ratio
            total_optimized_ratio += result.optimized_ratio
        
        avg_original_ratio = total_original_ratio / len(results) if results else 0
        avg_optimized_ratio = total_optimized_ratio / len(results) if results else 0
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_files': len(results),
            'average_original_ratio': avg_original_ratio,
            'average_optimized_ratio': avg_optimized_ratio,
            'improvement': avg_optimized_ratio - avg_original_ratio,
            'results': [vars(result) for result in results]
        }

def main():
    """ä¸»å‡½æ•°"""
    project_root = Path.cwd()
    optimizer = BilingualOptimizer(project_root)
    
    print("ğŸ” åˆ†æåŒè¯­æƒ…å†µ...")
    report = optimizer.generate_report()
    
    print(f"ğŸ“Š åŒè¯­ä¼˜åŒ–æŠ¥å‘Š / Bilingual Optimization Report")
    print(f"æ€»æ–‡ä»¶æ•°: {report['total_files']}")
    print(f"å¹³å‡åŸå§‹åŒè¯­æ¯”ä¾‹: {report['average_original_ratio']:.2%}")
    print(f"å¹³å‡ä¼˜åŒ–ååŒè¯­æ¯”ä¾‹: {report['average_optimized_ratio']:.2%}")
    print(f"æ”¹è¿›å¹…åº¦: {report['improvement']:.2%}")
    
    print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for result in report['results']:
        print(f"- {result['file_path']}: {result['original_ratio']:.2%} -> {result['optimized_ratio']:.2%}")
        if result['improvements']:
            print(f"  æ”¹è¿›: {', '.join(result['improvements'])}")
        if result['suggestions']:
            print(f"  å»ºè®®: {', '.join(result['suggestions'])}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = project_root / "reports" / f"bilingual_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    report_file.parent.mkdir(exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    main() 