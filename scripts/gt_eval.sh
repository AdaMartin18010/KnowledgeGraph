#!/bin/bash

# å›¾è®ºæ¨¡å—è¯„æµ‹è„šæœ¬ / Graph Theory Evaluation Script
# ä½œè€… / Author: KnowledgeGraph Team
# ç‰ˆæœ¬ / Version: 1.0.0

set -e

# é¢œè‰²å®šä¹‰ / Color Definitions
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•° / Logging Functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç¯å¢ƒ / Check Environment
check_environment() {
    log_info "æ£€æŸ¥å›¾è®ºè¯„æµ‹ç¯å¢ƒ / Checking Graph Theory evaluation environment..."
    
    # æ£€æŸ¥Pythonç¯å¢ƒ / Check Python environment
    if ! command -v python &> /dev/null; then
        log_error "Pythonæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
        exit 1
    fi
    
    # æ£€æŸ¥å¿…è¦çš„PythonåŒ… / Check required Python packages
    python -c "
import torch
import dgl
import networkx
import matplotlib
import numpy
print('æ‰€æœ‰å¿…è¦çš„åŒ…éƒ½å·²å®‰è£… / All required packages are installed')
" 2>/dev/null || {
        log_error "ç¼ºå°‘å¿…è¦çš„PythonåŒ…ï¼Œè¯·å®‰è£…ä¾èµ–"
        exit 1
    }
    
    log_success "ç¯å¢ƒæ£€æŸ¥é€šè¿‡ / Environment check passed"
}

# è¿è¡Œå›¾è®ºè¯„æµ‹ / Run Graph Theory Evaluation
run_evaluation() {
    log_info "å¼€å§‹å›¾è®ºè¯„æµ‹ / Starting Graph Theory evaluation..."
    
    # åˆ›å»ºç»“æœç›®å½• / Create results directory
    mkdir -p results/graph-theory
    
    # è¿è¡Œè¯„æµ‹è„šæœ¬ / Run evaluation script
    python << 'EOF'
import torch
import dgl
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import time
import json
from datetime import datetime

print("=== å›¾è®ºæ¨¡å—è¯„æµ‹ / Graph Theory Module Evaluation ===")
print(f"è¯„æµ‹æ—¶é—´ / Evaluation Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# 1. ç¯å¢ƒä¿¡æ¯ / Environment Information
print("1. ç¯å¢ƒä¿¡æ¯ / Environment Information")
print(f"   Pythonç‰ˆæœ¬ / Python Version: {torch.version.__version__}")
print(f"   PyTorchç‰ˆæœ¬ / PyTorch Version: {torch.__version__}")
print(f"   DGLç‰ˆæœ¬ / DGL Version: {dgl.__version__}")
print(f"   NetworkXç‰ˆæœ¬ / NetworkX Version: {nx.__version__}")
print(f"   CUDAå¯ç”¨ / CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"   CUDAç‰ˆæœ¬ / CUDA Version: {torch.version.cuda}")
    print(f"   GPUæ•°é‡ / GPU Count: {torch.cuda.device_count()}")
print()

# 2. å›¾ç»“æ„åˆ›å»ºæµ‹è¯• / Graph Structure Creation Test
print("2. å›¾ç»“æ„åˆ›å»ºæµ‹è¯• / Graph Structure Creation Test")
start_time = time.time()
try:
    # åˆ›å»ºNetworkXå›¾ / Create NetworkX graph
    G_nx = nx.erdos_renyi_graph(100, 0.1)
    nx_time = time.time() - start_time
    print(f"   âœ… NetworkXå›¾åˆ›å»ºæˆåŠŸ / NetworkX graph created successfully")
    print(f"   èŠ‚ç‚¹æ•°é‡ / Node count: {G_nx.number_of_nodes()}")
    print(f"   è¾¹æ•°é‡ / Edge count: {G_nx.number_of_edges()}")
    print(f"   åˆ›å»ºæ—¶é—´ / Creation time: {nx_time:.4f}s")
except Exception as e:
    print(f"   âŒ NetworkXå›¾åˆ›å»ºå¤±è´¥ / NetworkX graph creation failed: {e}")
print()

# 3. DGLå›¾åˆ›å»ºæµ‹è¯• / DGL Graph Creation Test
print("3. DGLå›¾åˆ›å»ºæµ‹è¯• / DGL Graph Creation Test")
start_time = time.time()
try:
    # åˆ›å»ºDGLå›¾ / Create DGL graph
    src = torch.randint(0, 100, (200,))
    dst = torch.randint(0, 100, (200,))
    G_dgl = dgl.graph((src, dst), num_nodes=100)
    dgl_time = time.time() - start_time
    print(f"   âœ… DGLå›¾åˆ›å»ºæˆåŠŸ / DGL graph created successfully")
    print(f"   èŠ‚ç‚¹æ•°é‡ / Node count: {G_dgl.number_of_nodes()}")
    print(f"   è¾¹æ•°é‡ / Edge count: {G_dgl.number_of_edges()}")
    print(f"   åˆ›å»ºæ—¶é—´ / Creation time: {dgl_time:.4f}s")
except Exception as e:
    print(f"   âŒ DGLå›¾åˆ›å»ºå¤±è´¥ / DGL graph creation failed: {e}")
print()

# 4. å›¾ç®—æ³•æµ‹è¯• / Graph Algorithm Test
print("4. å›¾ç®—æ³•æµ‹è¯• / Graph Algorithm Test")
try:
    # æœ€çŸ­è·¯å¾„ç®—æ³• / Shortest path algorithm
    start_time = time.time()
    path = nx.shortest_path(G_nx, 0, 50)
    sp_time = time.time() - start_time
    print(f"   âœ… æœ€çŸ­è·¯å¾„ç®—æ³•æˆåŠŸ / Shortest path algorithm successful")
    print(f"   è·¯å¾„é•¿åº¦ / Path length: {len(path)}")
    print(f"   è®¡ç®—æ—¶é—´ / Computation time: {sp_time:.4f}s")
    
    # è¿é€šåˆ†é‡ç®—æ³• / Connected components algorithm
    start_time = time.time()
    components = list(nx.connected_components(G_nx))
    cc_time = time.time() - start_time
    print(f"   âœ… è¿é€šåˆ†é‡ç®—æ³•æˆåŠŸ / Connected components algorithm successful")
    print(f"   è¿é€šåˆ†é‡æ•°é‡ / Component count: {len(components)}")
    print(f"   è®¡ç®—æ—¶é—´ / Computation time: {cc_time:.4f}s")
    
    # ä¸­å¿ƒæ€§ç®—æ³• / Centrality algorithm
    start_time = time.time()
    centrality = nx.betweenness_centrality(G_nx)
    bc_time = time.time() - start_time
    print(f"   âœ… ä¸­å¿ƒæ€§ç®—æ³•æˆåŠŸ / Centrality algorithm successful")
    print(f"   è®¡ç®—æ—¶é—´ / Computation time: {bc_time:.4f}s")
    
except Exception as e:
    print(f"   âŒ å›¾ç®—æ³•æµ‹è¯•å¤±è´¥ / Graph algorithm test failed: {e}")
print()

# 5. å›¾ç¥ç»ç½‘ç»œæµ‹è¯• / Graph Neural Network Test
print("5. å›¾ç¥ç»ç½‘ç»œæµ‹è¯• / Graph Neural Network Test")
try:
    # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾ / Create node features
    node_features = torch.randn(100, 16)
    G_dgl.ndata['feat'] = node_features
    
    # ç®€å•çš„å›¾å·ç§¯å±‚ / Simple graph convolution layer
    class SimpleGCN(torch.nn.Module):
        def __init__(self, in_dim, out_dim):
            super(SimpleGCN, self).__init__()
            self.linear = torch.nn.Linear(in_dim, out_dim)
        
        def forward(self, g, features):
            g.ndata['h'] = features
            g.update_all(dgl.function.copy_u('h', 'm'), dgl.function.sum('m', 'h'))
            return self.linear(g.ndata['h'])
    
    model = SimpleGCN(16, 8)
    start_time = time.time()
    output = model(G_dgl, node_features)
    gnn_time = time.time() - start_time
    print(f"   âœ… å›¾ç¥ç»ç½‘ç»œæµ‹è¯•æˆåŠŸ / Graph Neural Network test successful")
    print(f"   è¾“å‡ºç»´åº¦ / Output dimension: {output.shape}")
    print(f"   æ¨ç†æ—¶é—´ / Inference time: {gnn_time:.4f}s")
    
except Exception as e:
    print(f"   âŒ å›¾ç¥ç»ç½‘ç»œæµ‹è¯•å¤±è´¥ / Graph Neural Network test failed: {e}")
print()

# 6. æ€§èƒ½åŸºå‡† / Performance Benchmark
print("6. æ€§èƒ½åŸºå‡† / Performance Benchmark")

# å¤§è§„æ¨¡å›¾æµ‹è¯• / Large-scale graph test
sizes = [100, 500, 1000]
creation_times = []
algorithm_times = []

for size in sizes:
    # åˆ›å»ºå›¾ / Create graph
    start_time = time.time()
    G_large = nx.erdos_renyi_graph(size, 0.1)
    creation_time = time.time() - start_time
    creation_times.append(creation_time)
    
    # ç®—æ³•æµ‹è¯• / Algorithm test
    start_time = time.time()
    nx.shortest_path(G_large, 0, min(50, size-1))
    algorithm_time = time.time() - start_time
    algorithm_times.append(algorithm_time)
    
    print(f"   å›¾å¤§å° {size}: åˆ›å»º {creation_time:.4f}s, ç®—æ³• {algorithm_time:.4f}s")

print()
print(f"   å¹³å‡åˆ›å»ºæ—¶é—´ / Average creation time: {np.mean(creation_times):.4f}s")
print(f"   å¹³å‡ç®—æ³•æ—¶é—´ / Average algorithm time: {np.mean(algorithm_times):.4f}s")

# ä¿å­˜ç»“æœ / Save results
results = {
    "evaluation_time": datetime.now().isoformat(),
    "environment": {
        "python_version": torch.version.__version__,
        "pytorch_version": torch.__version__,
        "dgl_version": dgl.__version__,
        "networkx_version": nx.__version__,
        "cuda_available": torch.cuda.is_available()
    },
    "tests": {
        "networkx_graph": "PASS" if 'G_nx' in locals() else "FAIL",
        "dgl_graph": "PASS" if 'G_dgl' in locals() else "FAIL",
        "graph_algorithms": "PASS" if 'path' in locals() else "FAIL",
        "gnn_test": "PASS" if 'output' in locals() else "FAIL"
    },
    "performance": {
        "graph_sizes": sizes,
        "creation_times": creation_times,
        "algorithm_times": algorithm_times,
        "average_creation_time": float(np.mean(creation_times)),
        "average_algorithm_time": float(np.mean(algorithm_times))
    }
}

with open("results/graph-theory/evaluation_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print()
print("=== è¯„æµ‹å®Œæˆ / Evaluation Completed ===")
print(f"ç»“æœå·²ä¿å­˜åˆ°: results/graph-theory/evaluation_results.json")
EOF

    log_success "å›¾è®ºè¯„æµ‹å®Œæˆ / Graph Theory evaluation completed"
}

# æ˜¾ç¤ºç»“æœ / Show Results
show_results() {
    log_info "è¯„æµ‹ç»“æœ / Evaluation Results:"
    
    if [ -f "results/graph-theory/evaluation_results.json" ]; then
        echo ""
        echo "ğŸ“Š è¯¦ç»†ç»“æœ / Detailed Results:"
        cat results/graph-theory/evaluation_results.json | python -m json.tool
    else
        log_warning "æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ / Results file not found"
    fi
}

# ä¸»å‡½æ•° / Main function
main() {
    log_info "å¼€å§‹å›¾è®ºæ¨¡å—è¯„æµ‹ / Starting Graph Theory module evaluation"
    echo ""
    
    # æ£€æŸ¥ç¯å¢ƒ / Check environment
    check_environment
    
    # è¿è¡Œè¯„æµ‹ / Run evaluation
    run_evaluation
    
    # æ˜¾ç¤ºç»“æœ / Show results
    show_results
    
    log_success "å›¾è®ºæ¨¡å—è¯„æµ‹å®Œæˆï¼/ Graph Theory module evaluation completed!"
}

# é”™è¯¯å¤„ç† / Error handling
trap 'log_error "è¯„æµ‹æ‰§è¡Œå¤±è´¥ã€‚è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•° / Execute main function
main "$@"
