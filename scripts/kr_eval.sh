#!/bin/bash

# çŸ¥è¯†è¡¨ç¤ºæ¨¡å—è¯„æµ‹è„šæœ¬ / Knowledge Representation Evaluation Script
# ä½œè€… / Author: KnowledgeGraph Team
# ç‰ˆæœ¬ / Version: 1.0.0

set -e

# é¢œè‰²å®šä¹‰ / Color Definitions
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•° / Logging Functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç¯å¢ƒ / Check Environment
check_environment() {
    log_info "æ£€æŸ¥çŸ¥è¯†è¡¨ç¤ºè¯„æµ‹ç¯å¢ƒ / Checking Knowledge Representation evaluation environment..."
    
    # æ£€æŸ¥Pythonç¯å¢ƒ / Check Python environment
    if ! command -v python &> /dev/null; then
        log_error "Pythonæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
        exit 1
    fi
    
    # æ£€æŸ¥å¿…è¦çš„PythonåŒ… / Check required Python packages
    python -c "
import torch
import transformers
import sentence_transformers
import networkx
import rdflib
print('æ‰€æœ‰å¿…è¦çš„åŒ…éƒ½å·²å®‰è£… / All required packages are installed')
" 2>/dev/null || {
        log_error "ç¼ºå°‘å¿…è¦çš„PythonåŒ…ï¼Œè¯·å®‰è£…ä¾èµ–"
        exit 1
    }
    
    log_success "ç¯å¢ƒæ£€æŸ¥é€šè¿‡ / Environment check passed"
}

# è¿è¡ŒçŸ¥è¯†è¡¨ç¤ºè¯„æµ‹ / Run Knowledge Representation Evaluation
run_evaluation() {
    log_info "å¼€å§‹çŸ¥è¯†è¡¨ç¤ºè¯„æµ‹ / Starting Knowledge Representation evaluation..."
    
    # åˆ›å»ºç»“æœç›®å½• / Create results directory
    mkdir -p results/knowledge-representation
    
    # è¿è¡Œè¯„æµ‹è„šæœ¬ / Run evaluation script
    python << 'EOF'
import torch
import transformers
import sentence_transformers
import networkx as nx
import rdflib
import time
import json
from datetime import datetime

print("=== çŸ¥è¯†è¡¨ç¤ºæ¨¡å—è¯„æµ‹ / Knowledge Representation Module Evaluation ===")
print(f"è¯„æµ‹æ—¶é—´ / Evaluation Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# 1. ç¯å¢ƒä¿¡æ¯ / Environment Information
print("1. ç¯å¢ƒä¿¡æ¯ / Environment Information")
print(f"   Pythonç‰ˆæœ¬ / Python Version: {torch.version.__version__}")
print(f"   PyTorchç‰ˆæœ¬ / PyTorch Version: {torch.__version__}")
print(f"   CUDAå¯ç”¨ / CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"   CUDAç‰ˆæœ¬ / CUDA Version: {torch.version.cuda}")
    print(f"   GPUæ•°é‡ / GPU Count: {torch.cuda.device_count()}")
print()

# 2. æ¨¡å‹åŠ è½½æµ‹è¯• / Model Loading Test
print("2. æ¨¡å‹åŠ è½½æµ‹è¯• / Model Loading Test")
start_time = time.time()
try:
    model = sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2')
    load_time = time.time() - start_time
    print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ / Model loaded successfully")
    print(f"   åŠ è½½æ—¶é—´ / Loading time: {load_time:.2f}s")
except Exception as e:
    print(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥ / Model loading failed: {e}")
print()

# 3. æ–‡æœ¬åµŒå…¥æµ‹è¯• / Text Embedding Test
print("3. æ–‡æœ¬åµŒå…¥æµ‹è¯• / Text Embedding Test")
test_texts = [
    "çŸ¥è¯†å›¾è°±æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦æŠ€æœ¯",
    "Knowledge Graph is an important AI technology",
    "è¯­ä¹‰è¡¨ç¤ºå­¦ä¹ æ˜¯æ ¸å¿ƒä»»åŠ¡"
]
start_time = time.time()
try:
    embeddings = model.encode(test_texts)
    embed_time = time.time() - start_time
    print(f"   âœ… æ–‡æœ¬åµŒå…¥æˆåŠŸ / Text embedding successful")
    print(f"   åµŒå…¥ç»´åº¦ / Embedding dimension: {embeddings.shape}")
    print(f"   å¤„ç†æ—¶é—´ / Processing time: {embed_time:.2f}s")
except Exception as e:
    print(f"   âŒ æ–‡æœ¬åµŒå…¥å¤±è´¥ / Text embedding failed: {e}")
print()

# 4. å›¾ç»“æ„æµ‹è¯• / Graph Structure Test
print("4. å›¾ç»“æ„æµ‹è¯• / Graph Structure Test")
try:
    G = nx.Graph()
    G.add_edge("å®ä½“1", "å®ä½“2", relation="å…³ç³»")
    G.add_edge("å®ä½“2", "å®ä½“3", relation="å…³ç³»")
    print(f"   âœ… å›¾ç»“æ„åˆ›å»ºæˆåŠŸ / Graph structure created successfully")
    print(f"   èŠ‚ç‚¹æ•°é‡ / Node count: {G.number_of_nodes()}")
    print(f"   è¾¹æ•°é‡ / Edge count: {G.number_of_edges()}")
except Exception as e:
    print(f"   âŒ å›¾ç»“æ„åˆ›å»ºå¤±è´¥ / Graph structure creation failed: {e}")
print()

# 5. RDFå¤„ç†æµ‹è¯• / RDF Processing Test
print("5. RDFå¤„ç†æµ‹è¯• / RDF Processing Test")
try:
    g = rdflib.Graph()
    g.add((rdflib.URIRef("http://example.org/entity1"), 
            rdflib.URIRef("http://example.org/relation"), 
            rdflib.URIRef("http://example.org/entity2")))
    print(f"   âœ… RDFå¤„ç†æˆåŠŸ / RDF processing successful")
    print(f"   RDFä¸‰å…ƒç»„æ•°é‡ / RDF triple count: {len(g)}")
except Exception as e:
    print(f"   âŒ RDFå¤„ç†å¤±è´¥ / RDF processing failed: {e}")
print()

# 6. æ€§èƒ½åŸºå‡† / Performance Benchmark
print("6. æ€§èƒ½åŸºå‡† / Performance Benchmark")
benchmark_texts = ["æµ‹è¯•æ–‡æœ¬" + str(i) for i in range(100)]
start_time = time.time()
embeddings = model.encode(benchmark_texts)
total_time = time.time() - start_time
avg_time = total_time / len(benchmark_texts)
print(f"   æ‰¹é‡å¤„ç†100ä¸ªæ–‡æœ¬ / Batch processing 100 texts")
print(f"   æ€»æ—¶é—´ / Total time: {total_time:.2f}s")
print(f"   å¹³å‡æ—¶é—´ / Average time: {avg_time:.4f}s per text")
print(f"   ååé‡ / Throughput: {len(benchmark_texts)/total_time:.1f} texts/s")

# ä¿å­˜ç»“æœ / Save results
results = {
    "evaluation_time": datetime.now().isoformat(),
    "environment": {
        "python_version": torch.version.__version__,
        "pytorch_version": torch.__version__,
        "cuda_available": torch.cuda.is_available()
    },
    "tests": {
        "model_loading": "PASS" if 'model' in locals() else "FAIL",
        "text_embedding": "PASS" if 'embeddings' in locals() else "FAIL",
        "graph_structure": "PASS" if 'G' in locals() else "FAIL",
        "rdf_processing": "PASS" if 'g' in locals() else "FAIL"
    },
    "performance": {
        "batch_size": len(benchmark_texts),
        "total_time": total_time,
        "throughput": len(benchmark_texts)/total_time
    }
}

with open("results/knowledge-representation/evaluation_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print()
print("=== è¯„æµ‹å®Œæˆ / Evaluation Completed ===")
print(f"ç»“æœå·²ä¿å­˜åˆ°: results/knowledge-representation/evaluation_results.json")
EOF

    log_success "çŸ¥è¯†è¡¨ç¤ºè¯„æµ‹å®Œæˆ / Knowledge Representation evaluation completed"
}

# æ˜¾ç¤ºç»“æœ / Show Results
show_results() {
    log_info "è¯„æµ‹ç»“æœ / Evaluation Results:"
    
    if [ -f "results/knowledge-representation/evaluation_results.json" ]; then
        echo ""
        echo "ğŸ“Š è¯¦ç»†ç»“æœ / Detailed Results:"
        cat results/knowledge-representation/evaluation_results.json | python -m json.tool
    else
        log_warning "æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ / Results file not found"
    fi
}

# ä¸»å‡½æ•° / Main function
main() {
    log_info "å¼€å§‹çŸ¥è¯†è¡¨ç¤ºæ¨¡å—è¯„æµ‹ / Starting Knowledge Representation module evaluation"
    echo ""
    
    # æ£€æŸ¥ç¯å¢ƒ / Check environment
    check_environment
    
    # è¿è¡Œè¯„æµ‹ / Run evaluation
    run_evaluation
    
    # æ˜¾ç¤ºç»“æœ / Show results
    show_results
    
    log_success "çŸ¥è¯†è¡¨ç¤ºæ¨¡å—è¯„æµ‹å®Œæˆï¼/ Knowledge Representation module evaluation completed!"
}

# é”™è¯¯å¤„ç† / Error handling
trap 'log_error "è¯„æµ‹æ‰§è¡Œå¤±è´¥ã€‚è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•° / Execute main function
main "$@"
